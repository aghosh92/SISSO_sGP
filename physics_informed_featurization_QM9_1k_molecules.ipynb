{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aghosh92/SISSO_sGP/blob/main/physics_informed_featurization_QM9_1k_molecules.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This notebook shows how to generate ocmbination of nonlinear funtionalized features and rank them. The dataset used here contains the first 1,000 molecules as present in QM9 dataset.\n",
        "\n",
        "This is the first step to generate meaningful hypotheses.\n",
        "\n",
        "Notebook prepared by Ayana Ghosh\n",
        "\n",
        "Email: research.aghosh@gmail.com"
      ],
      "metadata": {
        "id": "vZdER7-2Mskt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnwTDb3TaloZ"
      },
      "source": [
        "Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST8V3gzxalob",
        "outputId": "a9208e1f-0226-4c2f-aef4-1dbf60e53aec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.4 MB 4.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 66 kB 3.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 36.0 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 98 kB 8.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 109 kB 39.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 515 kB 75.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 70 kB 8.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 561 kB 44.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 235 kB 71.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 555 kB 73.8 MB/s \n",
            "\u001b[?25h  Building wheel for pymatgen (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 463 kB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 265 kB 67.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 896 kB 36.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.0 MB 47.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 43.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 47.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 269 kB 9.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 139 kB 42.4 MB/s \n",
            "\u001b[?25h  Building wheel for matminer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pymatgen (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for skrebate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tpot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pydispatcher (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for stopit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.22.2 which is incompatible.\n",
            "mp-api 0.30.5 requires pymatgen>=2022.3.7, but you have pymatgen 2020.1.28 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.2 which is incompatible.\n",
            "emmet-core 0.39.6 requires pymatgen<2023.0,>=2021.3, but you have pymatgen 2020.1.28 which is incompatible.\n",
            "dask 2022.2.1 requires pyyaml>=5.3.1, but you have pyyaml 5.1.2 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -q matminer \n",
        "!pip install -q automatminer "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dK-gAA2caloe"
      },
      "source": [
        "Import essential packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KosB4L-alof",
        "outputId": "65d3ceb1-1cb2-4bb3-ad3d-13a941d812f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.unsupervised module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "from sklearn.linear_model import Lasso\n",
        "from matminer.featurizers.function import FunctionFeaturizer\n",
        "from automatminer import DataCleaner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YEBT-VDNaloj"
      },
      "outputs": [],
      "source": [
        "#@title Helper functions for featurization\n",
        "def get_data(selected_feature_list):\n",
        "    \n",
        "    function_featurizer = FunctionFeaturizer(multi_feature_depth=2,combo_function=np.sum)\n",
        "    function_featurizer.set_n_jobs(4)\n",
        "    function_featurizer=function_featurizer.fit(df_x[selected_feature_list])\n",
        "    df_combined=function_featurizer.featurize_dataframe(df_x[selected_feature_list],selected_feature_list)\n",
        "\n",
        "    df_combined[target] = df[target]\n",
        "    df_combined=df_combined.replace([np.inf,-np.inf],np.nan)\n",
        "    df_combined=df_combined.dropna(axis=1)\n",
        "    df_combined=df_combined.drop(columns=selected_feature_list,axis=1)\n",
        "    #save file \n",
        "    #df_combined.to_csv('filename.csv')\n",
        "\n",
        "    P = df_combined[target].values\n",
        "    df_combined = df_combined.loc[:, df_combined.columns != target]\n",
        "\n",
        "    return P, df_combined\n",
        "\n",
        "def lasso_fit(lam, P, D, feature_list):\n",
        "    #LASSO\n",
        "    #D_standardized = ss.zscore(D)\n",
        "    lasso =  Lasso(alpha=lam)\n",
        "    lasso.fit(D, P) \n",
        "    coef =  lasso.coef_\n",
        "    \n",
        "    # get strings of selected features\n",
        "    selected_indices = coef.nonzero()[0]\n",
        "    selected_features = [feature_list[i] for i in selected_indices]\n",
        "    \n",
        "    # get RMSE of LASSO model\n",
        "    P_predict = lasso.predict(D)\n",
        "\n",
        "    return coef,selected_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmO7BS9dlWQs"
      },
      "source": [
        "Mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czBvvgGmlX77",
        "outputId": "8102e39f-2802-4509-ea99-142f47ec52c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PflVF58MlHu8"
      },
      "source": [
        "Read in dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=18rx5GgyJoXE7os5hA3qDuFCH9BS3ZNWy\n",
        "df = pd.read_csv('/content/featurized_1k.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMS4Z8bTNQZJ",
        "outputId": "13a1445c-8139-4d4c-8921-e7551e26018b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18rx5GgyJoXE7os5hA3qDuFCH9BS3ZNWy\n",
            "To: /content/featurized_1k.csv\n",
            "\r  0% 0.00/90.0k [00:00<?, ?B/s]\r100% 90.0k/90.0k [00:00<00:00, 54.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPAdksrFemJ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae1cd90a-bd07-43f4-bd24-65246dbf6c91"
      },
      "source": [
        "# #df_valid = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/molecules_feat/featurized_3k_test.csv')\n",
        "# !gdown https://drive.google.com/uc?id=1Ax4_-8gdjgKdzByNQF4kK2o0jrIUuWrU\n",
        "# df_valid = pd.read_csv('/content/featurized_3k_test.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Ax4_-8gdjgKdzByNQF4kK2o0jrIUuWrU\n",
            "To: /content/featurized_3k_test.csv\n",
            "\r  0% 0.00/253k [00:00<?, ?B/s]\r100% 253k/253k [00:00<00:00, 99.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feat_endp = ['smiles','tpsa', 'mol_wt', 'mole_logp', 'enthalpy']\n",
        "#df = pd.concat([df1[feat_endp], df_valid[feat_endp]])"
      ],
      "metadata": {
        "id": "tszwvp82NWkW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkMloqVrlqx5",
        "outputId": "e84c4a9a-b18b-480e-a7af-da5cecad5134"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'smiles', 'homo', 'lumo', 'gap', 'mol_wt', 'nhoh_ct',\n",
              "       'valence', 'mole_logp', 'tpsa', 'enthalpy'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "b1QqFZGRaloh"
      },
      "outputs": [],
      "source": [
        "target   = 'enthalpy'\n",
        "selected_feature_list = ['tpsa', 'mol_wt', 'mole_logp']\n",
        "df_x = df[selected_feature_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cxaZ0v_ImP9b"
      },
      "outputs": [],
      "source": [
        "selected_feature_list = df_x.columns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_feature_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKXFQDNpOyN8",
        "outputId": "b9e002cd-4e46-44c4-fac2-b6676e911bf9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['tpsa', 'mol_wt', 'mole_logp'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkJ9yu84thpk"
      },
      "source": [
        "This step takes a while to run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0UY1dPsalok",
        "outputId": "0898fac0-95e0-4a58-bd19-885d3af1f852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generating functionalized data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FunctionFeaturizer: 100%|██████████| 1000/1000 [07:26<00:00,  2.24it/s]\n"
          ]
        }
      ],
      "source": [
        "print('generating functionalized data...')\n",
        "P, df_D = get_data(selected_feature_list)\n",
        "features_list = df_D.columns.to_list()\n",
        "D = df_D.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "i3s8VA94alom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27f936e5-103f-48c3-8eca-2dd4cd88ebd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:474: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 52883.470413157636, tolerance: 85.48249451032828\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ],
      "source": [
        "alpha = 0.2\n",
        "\n",
        "coef, selected_features = lasso_fit(alpha, P, D, features_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zcKgRpURalon",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b2c0f49-4eca-45f8-ca22-e393da176b2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpha: 0.200\t dimension of descriptor: 116\n",
            "                        features  abs(nonzero_coefs_LASSO)\n",
            "64       mole_logp + 1/log(tpsa)                  6.191368\n",
            "68  exp(mole_logp) + 1/log(tpsa)                  2.027891\n",
            "65    mole_logp**2 + 1/log(tpsa)                  1.103968\n",
            "77        mole_logp + exp(-tpsa)                  0.811840\n",
            "81   exp(mole_logp) + exp(-tpsa)                  0.297845\n",
            "51     mole_logp**3 + sqrt(tpsa)                  0.244694\n",
            "48           mole_logp**3 + tpsa                  0.105495\n",
            "3                      mol_wt**2                  0.032640\n",
            "46            tpsa + 1/mole_logp                  0.022819\n",
            "0                        tpsa**2                  0.013248\n"
          ]
        }
      ],
      "source": [
        "print(\"alpha: %.3f\\t dimension of descriptor: %s\" \n",
        "      %(alpha, len(selected_features)))\n",
        "\n",
        "lasso_features=pd.DataFrame({'features':np.array(selected_features), \n",
        "                             'abs(nonzero_coefs_LASSO)': np.abs(coef[coef.nonzero()])}).sort_values(by='abs(nonzero_coefs_LASSO)',\n",
        "                                                                                                    ascending=False)\n",
        "print(lasso_features.head(n=10))\n",
        "# save the combinations of features\n",
        "#lasso_features.to_csv('filename.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87gUmz7y1z-E"
      },
      "source": [
        "We will use few of these combinations as analytical models after balancing dimensions to predict formation enthalpy (Hartree/g/mol) within Bayesian optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvCi1t2LmRmC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuPcgVCEJDJIqehJYWUSPj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}